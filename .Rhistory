m3 <- merge(books, authors, by.x = "name", by.y = "title")
m2 <- merge(books, authors, by.x = "name", by.y = "surname", all=TRUE)
m2
library(dplyr)
install.packages(dplyr)
install.packages("dplyr")
dir.create("week3Q")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", destfile="./week1=3Q/Q1/Q1.csv")
dir.create("./week3Q/Q1")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", destfile="./week1=3Q/Q1/Q1.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", destfile="./week13Q/Q1/Q1.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", destfile="./week3Q/Q1/Q1.csv")
Q1=read.csv("./week3Q/Q1/Q1.csv")
library(dplyr)
Q1select=Q1[(Q1$ACR=3 & Q1$AGS=6),]
Q1select=Q1[(Q1$ACR==3 & Q1$AGS==6),]
agricultureLogical=Q1select
which(agricultureLogical)
?which
which(agricultureLogical, arr.ind=TRUE)
agricultureLogical=table(Q1$ACR==3 & Q1$AGS==6)
which(agricultureLogical)
agricultureLogical=Q1$ACR==3 & Q1$AGS==6
which(agricultureLogical)
library("jpeg")
library(jpeg)
install.packages("jepg")
install.packages("jpeg")
Q2=readJPEG("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg")
library(jpeg)
Q2=readJPEG("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg")
x="https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
Q2=readJPEG(x)
Q2=readJPEG("http://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg")
Q2=readJPEG(x, native=TRUE)
Q2=readJPEG("./week3Q/Q2/getdata_jeff.jpg", native=TRUE)
quantile(Q2, prod=(0.3,0.8))
quantile(Q2, prod=c(0.3,0.8))
quantile(Q2, probs=c(0.3,0.8))
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv", destfile="./week13Q/Q3/Q3_1.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv", destfile="./week3Q/Q3/Q3_1.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv", destfile="./week3Q/Q3/Q3_1.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv", destfile="./week3Q/Q3/Q3_2.csv")
Q3_1=read.csv("./week3Q/Q3/Q3_1.csv")
Q3_2=read.csv("./week3Q/Q3/Q3_2.csv")
names(Q3_1)
names(Q3_2)
Q3_2[1,1]
Q3_1[1,]
Q3_1[1:4,]
Q3_1
names(Q3_2)
mergeQ3=(Q3_1,Q3_2,by.x="x", by.y="CountryCode",all=FALSE)
mergeQ3=(Q3_1, Q3_2, by.x="x", by.y="CountryCode",all=FALSE)
mergeQ3=merge(Q3_1, Q3_2, by.x="x", by.y="CountryCode",all=FALSE)
mergeQ3=merge(Q3_1, Q3_2, by.x="X", by.y="CountryCode",all=FALSE)
row(mergeQ3)
nrow(mergeQ3)
names(mergeQ3)
mergeQ3=merge(Q3_1, Q3_2, by.x="X", by.y="CountryCode",all=TRUE)
mergeQ3=merge(Q3_1, Q3_2, by.x="X", by.y="CountryCode",all=FALSE)
mergeQ3order=mergeQ3[mergeQ3$Gross.domestic.product.2012,]
mergeQ3order=mergeQ3[order(mergeQ3$Gross.domestic.product.2012),]
mergeQ3order[13,mergeQ3order$Gross.domestic.product.2012]
mergeQ3order$Gross.domestic.product.2012[[13]]
mergeQ3order=mergeQ3[order(mergeQ3$X.1),]
mergeQ3$CourntryCode[[13]]
head(Q3_1$CountryCode)
head(Q3_2$CountryCode)
Q3_2$CountryCode
names(Q3_1)
head(Q3_1)
names(Q3_1)
names(Q3_1)=c("CountryCode","Gross.domestic.product.2012","rankingGDP",
"Long.Name", "gdp","X.5","X.6","X.7","X.8")
head(Q3_1)
Q3_1=Q3_1(CountryCode!="")
Q3_1=Q3_1[CountryCode!=""]
Q3_1=Q3_1[CountryCode!=""]
names(Q3_1)
Q3_1=Q3_1[CountryCode!="",]
Q3_1=read.csv("./week3Q/Q3/Q3_1.csv")
Q3_2=read.csv("./week3Q/Q3/Q3_2.csv")
head(Q3_1)
Q3_1=Q3_1[X!="",]
Q3_1=Q3_1[X!=""]
Q3_1=read.csv("./week3Q/Q3/Q3_1.csv",skip = 4, nrows = 215)
Q3_1=Q3_1[X!=""]
Q3_1=Q3_1[Q3_1$X!="",]
mergeQ3=merge(Q3_2,Q3_1, by.x="CountryCode", by.y="X",all=FALSE)
mergeQ3=merge(Q3_2,Q3_1, by.x="CountryCode", by.y="X",all=TRUE)
Q3_1=read.csv("./week3Q/Q3/Q3_1.csv")
Q3_1=Q3_1[Q3_1$X!="",]
mergeQ3=merge(Q3_2,Q3_1, by.x="CountryCode", by.y="X",all=TRUE)
names(mergeQ3)
mergeQ3order=mergeQ3[order(mergeQ3$Gross.domestic.product.2012),]
mergeQ3order$CountryCode[[13]]
mergeQ3order$X.2[[13]]
mergeQ3order=mergeQ3[order(des(mergeQ3$Gross.domestic.product.2012),]
mergeQ3order=mergeQ3[sort(mergeQ3$Gross.domestic.product.2012,decreasing=TURE),]
mergeQ3order=mergeQ3[sort(mergeQ3$Gross.domestic.product.2012,decreasing=TRUE),]
mergeQ3order$X.2[[13]]
mergeQ3order$X.2[[228]]
mergeQ3order$X.2[[229]]
sum(!is.na(unique(mergeQ3$X.2)))
dtGDP <- data.table(read.csv("./week3Q/Q3/Q3_1.csv", skip = 4, nrows = 215))
library(data.table)
dtGDP <- data.table(read.csv("./week3Q/Q3/Q3_1.csv", skip = 4, nrows = 215))
dtGDP <- dtGDP[X != ""]
dtGDP <- dtGDP[, list(X, X.1, X.3, X.4)]
setnames(dtGDP, c("X", "X.1", "X.3", "X.4"), c("CountryCode", "rankingGDP",
"Long.Name", "gdp"))
dtEd <- data.table(read.csv("./week3Q/Q3/Q3_2.csv"))
dt <- merge(dtGDP, dtEd, all = TRUE, by = c("CountryCode"))
sum(!is.na(unique(dt$rankingGDP)))
Q3_1=read.csv("./week3Q/Q3/Q3_1.csv", skip = 4, nrows = 215)
Q3_2=read.csv("./week3Q/Q3/Q3_2.csv")
Q3_1=read.csv("./week3Q/Q3/Q3_1.csv")
mergeQ3=merge(Q3_2,Q3_1,by.x="CountryCode",by,y="X", all=FALSE)
mergeQ3=merge(Q3_2,Q3_1,by.x="CountryCode",by.y="X", all=FALSE)
Q3_1=read.csv("./week3Q/Q3/Q3_1.csv",stringsAsFactors=FALSE, header=FALSE)
mergeQ3=merge(Q3_2,Q3_1,by.x="CountryCode",by.y="X", all=FALSE)
names(Q3_1)
head(Q3_1)
Q3_1=read.csv("./week3Q/Q3/Q3_1.csv")
Q3_1=read.csv("./week3Q/Q3/Q3_1.csv", skip = 4, nrows = 215)
Q3_1=Q3_1[,C(Q3_1$X,Q3_1$X.1,Q3_1$X,3,Q3_1$X.4)]
mergeQ3=merge(Q3_2,Q3_1,by.x="CountryCode",by.y="X", all=FALSE)
mergeQ3$CountryCode
Q3_1=read.csv("./week3Q/Q3/Q3_1.csv")
class(Q3_1#X)
class(Q3_1$X)
class(Q3_1$X.1)
class(Q3_1$X.2)
class(Q3_1$X.3)
class(Q3_1$X.4)
class(Q3_2$CountryCode)
print ("the 'reshape2' package is required")
if (!file.exists("getdata_projectfiles_UCI HAR Dataset")) {
print (" The directory which includes required data, named "getdata_projectfiles_UCI HAR Dataset", is required!)
}
if (!file.exists("getdata_projectfiles_UCI HAR Dataset")) {
print (" The directory which includes required data, named 'getdata_projectfiles_UCI HAR Dataset', is required!)
}
if (!file.exists("getdata_projectfiles_UCI HAR Dataset")) {
print (" The directory which includes required data, named 'getdata_projectfiles_UCI HAR Dataset', is required!)
}
}
)
if (!file.exists("getdata_projectfiles_UCI HAR Dataset")) {
print ("wrong")}
if (!file.exists("getdata_projectfiles_UCI HAR Dataset")) {
print ("wrong")
}
if (!file.exists("getdata_projectfiles_UCI HAR Dataset")) {
if (!file.exists("getdata_projectfiles_UCI HAR Dataset")) {
print (" The directory which includes required data, named 'getdata_projectfiles_UCI HAR Dataset', is required!")
}
write.table(DataTidy, file="Project.txt", row.name=FALSE)
}
if (!file.exists("getdata_projectfiles_UCI HAR Dataset")) {
print (" The directory which includes required data, named 'getdata_projectfiles_UCI HAR Dataset', is required!")
}
# 1) a tidy data set as described below,
# 1) a tidy data set as described below,
# 2) a link to a Github repository with script for performing the analysis,
# 3) a code book that describes the variables, the data, and any transformations or work called CodeBook.md.
# 4) README.md in the repo with scripts is required explaining how all of the scripts work and how they are connected.
# please check the follows:
# anounce the required packages
print ("the 'reshape2' package is required")
# check the required data exists or not
if (!file.exists("getdata_projectfiles_UCI HAR Dataset")) {
print (" The directory which includes required data, named 'getdata_projectfiles_UCI HAR Dataset', is required!")
}else{
# read all test and trainning data into R
trainSet=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/train/X_train.txt")
testSet=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/test/X_test.txt")
# change the names of variables to feature names
ColumnNames=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/features.txt")
ColumnNames=ColumnNames[,2]
ColumnNames=as.character(ColumnNames)
names(trainSet)=ColumnNames
names(testSet)=ColumnNames
# read the files of labels and subjects into R and correct the names
testLable=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/test/y_test.txt")
trainLable=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/train/y_train.txt")
testSubject=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/test/subject_test.txt")
trainSubject=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/train/Subject_train.txt")
names(trainLable)="Label"
names(testLable)="Label"
names(trainSubject)="Subject"
names(testSubject)="Subject"
# create the integral data of test and trainning
trainData=cbind(trainLable,trainSubject,trainSet)
testData=cbind(testLable,testSubject,testSet)
# merge trainData and test Data into one data set
mergeData=rbind(trainData,testData)
# replace the code of label in mergeData with names shown in the activity_labels.txt
lables=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/activity_labels.txt")
names(lables)=c("Label","Names")
DataonLable=merge(lables,mergeData,by="Label",all=TRUE)
DataonLable=DataonLable[,2:564]
names(DataonLable)[[1]]="Label"
# subset DaraonLable into data only containing mean and standard deviation information.
DataSelect=subset(DataonLable, select=c("Label","Subject",colnames(DataonLable)[grep("mean()",colnames(DataonLable),fixed=TRUE)],colnames(DataonLable)[grep("std()",colnames(DataonLable),fixed=TRUE)]))
# create the final tidy data
library(reshape2)
DataReshape=melt(DataSelect, id=c("Label","Subject"))
DataTidy=dcast(DataReshape,Label+Subject~variable,mean)
# write DataTidy into Project.txt on disk
write.table(DataTiny, file="Project.txt", row.name=FALSE)
}
# The goal is to prepare tidy data that can be used for later analysis.
# In this project, following documents shoudl be submitted:
# 1) a tidy data set as described below,
# 2) a link to a Github repository with script for performing the analysis,
# 3) a code book that describes the variables, the data, and any transformations or work called CodeBook.md.
# 4) README.md in the repo with scripts is required explaining how all of the scripts work and how they are connected.
# please check the follows:
# anounce the required packages
print ("the 'reshape2' package is required")
# check the required data exists or not
if (!file.exists("getdata_projectfiles_UCI HAR Dataset")) {
print (" The directory which includes required data, named 'getdata_projectfiles_UCI HAR Dataset', is required!")
}else{
# read all test and trainning data into R
trainSet=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/train/X_train.txt")
testSet=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/test/X_test.txt")
# change the names of variables to feature names
ColumnNames=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/features.txt")
ColumnNames=ColumnNames[,2]
ColumnNames=as.character(ColumnNames)
names(trainSet)=ColumnNames
names(testSet)=ColumnNames
# read the files of labels and subjects into R and correct the names
testLable=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/test/y_test.txt")
trainLable=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/train/y_train.txt")
testSubject=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/test/subject_test.txt")
trainSubject=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/train/Subject_train.txt")
names(trainLable)="Label"
names(testLable)="Label"
names(trainSubject)="Subject"
names(testSubject)="Subject"
# create the integral data of test and trainning
trainData=cbind(trainLable,trainSubject,trainSet)
testData=cbind(testLable,testSubject,testSet)
# merge trainData and test Data into one data set
mergeData=rbind(trainData,testData)
# replace the code of label in mergeData with names shown in the activity_labels.txt
lables=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/activity_labels.txt")
names(lables)=c("Label","Names")
DataonLable=merge(lables,mergeData,by="Label",all=TRUE)
DataonLable=DataonLable[,2:564]
names(DataonLable)[[1]]="Label"
# subset DaraonLable into data only containing mean and standard deviation information.
DataSelect=subset(DataonLable, select=c("Label","Subject",colnames(DataonLable)[grep("mean()",colnames(DataonLable),fixed=TRUE)],colnames(DataonLable)[grep("std()",colnames(DataonLable),fixed=TRUE)]))
# create the final tidy data
library(reshape2)
DataReshape=melt(DataSelect, id=c("Label","Subject"))
DataTidy=dcast(DataReshape,Label+Subject~variable,mean)
# write DataTidy into Project.txt on disk
write.table(DataTiny, file="Project.txt", row.name=FALSE)
}
## The goal is to prepare tidy data that can be used for later analysis.
## In this project, following documents shoudl be submitted:
## 1) a tidy data set as described below,
# 2) a link to a Github repository with script for performing the analysis,
# 3) a code book that describes the variables, the data, and any transformations or work called CodeBook.md.
# 4) README.md in the repo with scripts is required explaining how all of the scripts work and how they are connected.
## please check the follows:
## anounce the required packages
print ("the 'reshape2' package is required")
## check the required data exists or not
if (!file.exists("getdata_projectfiles_UCI HAR Dataset")) {
print (" The directory which includes required data, named 'getdata_projectfiles_UCI HAR Dataset', is required!")
}else{
## read all test and trainning data into R
trainSet=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/train/X_train.txt")
testSet=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/test/X_test.txt")
## change the names of variables to feature names
ColumnNames=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/features.txt")
ColumnNames=ColumnNames[,2]
ColumnNames=as.character(ColumnNames)
names(trainSet)=ColumnNames
names(testSet)=ColumnNames
## read the files of labels and subjects into R and correct the names
testLable=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/test/y_test.txt")
trainLable=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/train/y_train.txt")
testSubject=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/test/subject_test.txt")
trainSubject=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/train/Subject_train.txt")
names(trainLable)="Label"
names(testLable)="Label"
names(trainSubject)="Subject"
names(testSubject)="Subject"
## create the integral data of test and trainning
trainData=cbind(trainLable,trainSubject,trainSet)
testData=cbind(testLable,testSubject,testSet)
## merge trainData and test Data into one data set
mergeData=rbind(trainData,testData)
## replace the code of label in mergeData with names shown in the activity_labels.txt
lables=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/activity_labels.txt")
names(lables)=c("Label","Names")
DataonLable=merge(lables,mergeData,by="Label",all=TRUE)
DataonLable=DataonLable[,2:564]
names(DataonLable)[[1]]="Label"
## subset DaraonLable into data only containing mean and standard deviation information.
DataSelect=subset(DataonLable, select=c("Label","Subject",colnames(DataonLable)[grep("mean()",colnames(DataonLable),fixed=TRUE)],colnames(DataonLable)[grep("std()",colnames(DataonLable),fixed=TRUE)]))
## create the final tidy data
library(reshape2)
DataReshape=melt(DataSelect, id=c("Label","Subject"))
DataTidy=dcast(DataReshape,Label+Subject~variable,mean)
## write DataTidy into Project.txt on disk
write.table(DataTiny, file="Project.txt", row.name=FALSE)
}
## The goal is to prepare tidy data that can be used for later analysis.
## In this project, following documents shoudl be submitted:
## 1) a tidy data set as described below,
# 2) a link to a Github repository with script for performing the analysis,
# 3) a code book that describes the variables, the data, and any transformations or work called CodeBook.md.
# 4) README.md in the repo with scripts is required explaining how all of the scripts work and how they are connected.
## please check the follows:
## anounce the required packages
if ("reshape2" %in% rownames(installed.packages()) == FALSE) {
print ("the 'reshape2' package is required")
}else{
## check the required data exists or not
if (!file.exists("getdata_projectfiles_UCI HAR Dataset")) {
print (" The directory which includes required data, named 'getdata_projectfiles_UCI HAR Dataset', is required!")
}else{
## read all test and trainning data into R
trainSet=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/train/X_train.txt")
testSet=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/test/X_test.txt")
## change the names of variables to feature names
ColumnNames=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/features.txt")
ColumnNames=ColumnNames[,2]
ColumnNames=as.character(ColumnNames)
names(trainSet)=ColumnNames
names(testSet)=ColumnNames
## read the files of labels and subjects into R and correct the names
testLable=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/test/y_test.txt")
trainLable=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/train/y_train.txt")
testSubject=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/test/subject_test.txt")
trainSubject=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/train/Subject_train.txt")
names(trainLable)="Label"
names(testLable)="Label"
names(trainSubject)="Subject"
names(testSubject)="Subject"
## create the integral data of test and trainning
trainData=cbind(trainLable,trainSubject,trainSet)
testData=cbind(testLable,testSubject,testSet)
## merge trainData and test Data into one data set
mergeData=rbind(trainData,testData)
## replace the code of label in mergeData with names shown in the activity_labels.txt
lables=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/activity_labels.txt")
names(lables)=c("Label","Names")
DataonLable=merge(lables,mergeData,by="Label",all=TRUE)
DataonLable=DataonLable[,2:564]
names(DataonLable)[[1]]="Label"
## subset DaraonLable into data only containing mean and standard deviation information.
DataSelect=subset(DataonLable, select=c("Label","Subject",colnames(DataonLable)[grep("mean()",colnames(DataonLable),fixed=TRUE)],colnames(DataonLable)[grep("std()",colnames(DataonLable),fixed=TRUE)]))
## create the final tidy data
library(reshape2)
DataReshape=melt(DataSelect, id=c("Label","Subject"))
DataTidy=dcast(DataReshape,Label+Subject~variable,mean)
## write DataTidy into Project.txt on disk
write.table(DataTiny, file="Project.txt", row.name=FALSE)
}
}
setwd("D:/MOOC/coursera/getting and cleaning data/data/project")
## The goal is to prepare tidy data that can be used for later analysis.
## In this project, following documents shoudl be submitted:
## 1) a tidy data set as described below,
# 2) a link to a Github repository with script for performing the analysis,
# 3) a code book that describes the variables, the data, and any transformations or work called CodeBook.md.
# 4) README.md in the repo with scripts is required explaining how all of the scripts work and how they are connected.
## please check the follows:
## anounce the required packages
if ("reshape2" %in% rownames(installed.packages()) == FALSE) {
print ("the 'reshape2' package is required")
}else{
## check the required data exists or not
if (!file.exists("getdata_projectfiles_UCI HAR Dataset")) {
print (" The directory which includes required data, named 'getdata_projectfiles_UCI HAR Dataset', is required!")
}else{
## read all test and trainning data into R
trainSet=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/train/X_train.txt")
testSet=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/test/X_test.txt")
## change the names of variables to feature names
ColumnNames=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/features.txt")
ColumnNames=ColumnNames[,2]
ColumnNames=as.character(ColumnNames)
names(trainSet)=ColumnNames
names(testSet)=ColumnNames
## read the files of labels and subjects into R and correct the names
testLable=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/test/y_test.txt")
trainLable=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/train/y_train.txt")
testSubject=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/test/subject_test.txt")
trainSubject=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/train/Subject_train.txt")
names(trainLable)="Label"
names(testLable)="Label"
names(trainSubject)="Subject"
names(testSubject)="Subject"
## create the integral data of test and trainning
trainData=cbind(trainLable,trainSubject,trainSet)
testData=cbind(testLable,testSubject,testSet)
## merge trainData and test Data into one data set
mergeData=rbind(trainData,testData)
## replace the code of label in mergeData with names shown in the activity_labels.txt
lables=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/activity_labels.txt")
names(lables)=c("Label","Names")
DataonLable=merge(lables,mergeData,by="Label",all=TRUE)
DataonLable=DataonLable[,2:564]
names(DataonLable)[[1]]="Label"
## subset DaraonLable into data only containing mean and standard deviation information.
DataSelect=subset(DataonLable, select=c("Label","Subject",colnames(DataonLable)[grep("mean()",colnames(DataonLable),fixed=TRUE)],colnames(DataonLable)[grep("std()",colnames(DataonLable),fixed=TRUE)]))
## create the final tidy data
library(reshape2)
DataReshape=melt(DataSelect, id=c("Label","Subject"))
DataTidy=dcast(DataReshape,Label+Subject~variable,mean)
## write DataTidy into Project.txt on disk
write.table(DataTiny, file="Project.txt", row.name=FALSE)
}
}
## The goal is to prepare tidy data that can be used for later analysis.
## In this project, following documents shoudl be submitted:
## 1) a tidy data set as described below,
# 2) a link to a Github repository with script for performing the analysis,
# 3) a code book that describes the variables, the data, and any transformations or work called CodeBook.md.
# 4) README.md in the repo with scripts is required explaining how all of the scripts work and how they are connected.
## please check the follows:
## anounce the required packages
if ("reshape2" %in% rownames(installed.packages()) == FALSE) {
print ("the 'reshape2' package is required")
}else{
## check the required data exists or not
if (!file.exists("getdata_projectfiles_UCI HAR Dataset")) {
print (" The directory which includes required data, named 'getdata_projectfiles_UCI HAR Dataset', is required!")
}else{
## read all test and trainning data into R
trainSet=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/train/X_train.txt")
testSet=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/test/X_test.txt")
## change the names of variables to feature names
ColumnNames=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/features.txt")
ColumnNames=ColumnNames[,2]
ColumnNames=as.character(ColumnNames)
names(trainSet)=ColumnNames
names(testSet)=ColumnNames
## read the files of labels and subjects into R and correct the names
testLable=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/test/y_test.txt")
trainLable=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/train/y_train.txt")
testSubject=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/test/subject_test.txt")
trainSubject=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/train/Subject_train.txt")
names(trainLable)="Label"
names(testLable)="Label"
names(trainSubject)="Subject"
names(testSubject)="Subject"
## create the integral data of test and trainning
trainData=cbind(trainLable,trainSubject,trainSet)
testData=cbind(testLable,testSubject,testSet)
## merge trainData and test Data into one data set
mergeData=rbind(trainData,testData)
## replace the code of label in mergeData with names shown in the activity_labels.txt
lables=read.table("./getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset/activity_labels.txt")
names(lables)=c("Label","Names")
DataonLable=merge(lables,mergeData,by="Label",all=TRUE)
DataonLable=DataonLable[,2:564]
names(DataonLable)[[1]]="Label"
## subset DaraonLable into data only containing mean and standard deviation information.
DataSelect=subset(DataonLable, select=c("Label","Subject",colnames(DataonLable)[grep("mean()",colnames(DataonLable),fixed=TRUE)],colnames(DataonLable)[grep("std()",colnames(DataonLable),fixed=TRUE)]))
## create the final tidy data
library(reshape2)
DataReshape=melt(DataSelect, id=c("Label","Subject"))
DataTidy=dcast(DataReshape,Label+Subject~variable,mean)
## write DataTidy into Project.txt on disk
write.table(DataTidy, file="Project.txt", row.name=FALSE)
}
}
check=read.table("Project.txt")
head(check)
source(run_analysis.R)
source("run_analysis.R")
setwd(../)
setwd("../")
source("./project/run_analysis.R")
install.packages("rmarkdown")
library(rmarkdown)
output: html_document
---
title: "code book for run_analysis"
author: "godsonhenry"
date: "Saturday, May 23, 2015"
output: html_document
---
This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.
When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:
```{r}
summary(cars)
```
You can also embed plots, for example:
```{r, echo=FALSE}
plot(cars)
```
Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
setwd("./project")
setwd("./run_analysis")
check=read.table("Project.txt")
names(check)
check=read.table("Project.txt",header=TRUE)
names(check)
names(check)[[3]]
head(check)
